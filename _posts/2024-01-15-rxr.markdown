---
layout: post
title:  "RxR: Rapid eXploration for Reinforcement Learning via Sampling-based Reset Distributions and Imitation Pre-training"
date:  2024-01-15 22:21:59 +00:00
image: rxr.gif
categories: research
author: "Gagan Khandate"
authors: "<strong>Gagan Khandate*</strong>, Tristan Luca Saidi*, Siqi Shang*, Eric Chang, Johnson Adams, Matei Ciocarlie"
venue: "Autonomous Robots - RSS 2023 Special Issue"
arxiv: https://arxiv.org/pdf/2401.15484
website: https://sbrl.cs.columbia.edu
# slides: /pdfs/jcdl2019.pdf
# code: https://github.com/leonidk/venue_scores
---
We present a method for enabling Reinforcement Learning of motor control policies for complex skills such as dexterous manipulation. We posit that a key difficulty for training such policies is the difficulty of exploring the problem state space, as the accessible and useful regions of this space form a complex structure along manifolds of the original high-dimensional state space. This work presents a method to enable and support exploration with Sampling-based Planning. We use a generally applicable non-holonomic Rapidly-exploring Random Trees algorithm and present multiple methods to use the resulting structure to bootstrap model-free Reinforcement Learning. Our method is effective at learning various challenging dexterous motor control skills of higher difficulty than previously shown. In particular, we achieve dexterous in-hand manipulation of complex objects while simultaneously securing the object without the use of passive support surfaces. These policies also transfer effectively to real robots. A number of example videos can also be found on the project website: https://sbrl.cs.columbia.edu